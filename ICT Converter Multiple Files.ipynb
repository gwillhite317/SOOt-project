{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3466582f",
   "metadata": {},
   "source": [
    "# ICT Converter Function"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b97c24bb",
   "metadata": {},
   "source": [
    "Changed: added line 106 and 107 to avoid errors with weird characters, added line 148 to keep the seconds value for start time from metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "8174e454",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.makedirs(\"icartt\", exist_ok=True)\n",
    "\n",
    "from __future__ import annotations\n",
    "\n",
    "from dataclasses import dataclass\n",
    "from pathlib import Path\n",
    "from typing import Dict, List, Optional, Tuple, Union\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "PathLike = Union[str, Path]\n",
    "\n",
    "\n",
    "@dataclass(frozen=True)\n",
    "class ICARTTInfo:\n",
    "    path: Path\n",
    "    header_length: int\n",
    "    ffi: str\n",
    "\n",
    "\n",
    "@dataclass(frozen=True)\n",
    "class VariableDef:\n",
    "    name: str\n",
    "    unit: Optional[str] = None\n",
    "    description: Optional[str] = None\n",
    "    missing: Optional[float] = None  # per-variable missing, if known\n",
    "\n",
    "\n",
    "class ICARTTReader:\n",
    "    \"\"\"\n",
    "    General ICARTT/ICT reader.\n",
    "\n",
    "    Goals:\n",
    "      - Robustly read the data table (CSV-like) for typical ICT files.\n",
    "      - Avoid file-specific assumptions (campaign/platform/column names).\n",
    "      - Provide best-effort metadata parsing (especially for FFI=1001) but\n",
    "        never let metadata parsing prevent data extraction.\n",
    "\n",
    "    Notes:\n",
    "      - Many airborne ICT files are FFI=1001 (1D time series), but other FFIs exist.\n",
    "      - Header length is always the first token on the first line in the files you've shown.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, path: PathLike):\n",
    "        self.path = Path(path)\n",
    "        self.info = self._read_info()\n",
    "\n",
    "    # ----------------------------\n",
    "    # Core: file format info\n",
    "    # ----------------------------\n",
    "    def _read_info(self) -> ICARTTInfo:\n",
    "        with open(self.path, \"r\", encoding=\"utf-8\", errors=\"ignore\") as f:\n",
    "            line1 = f.readline().strip()\n",
    "\n",
    "        parts = [p.strip() for p in line1.split(\",\")]\n",
    "        if len(parts) < 2:\n",
    "            raise ValueError(f\"Unexpected ICARTT first line format: {line1!r}\")\n",
    "\n",
    "        header_length = int(parts[0])\n",
    "        ffi = parts[1]\n",
    "        return ICARTTInfo(path=self.path, header_length=header_length, ffi=ffi)\n",
    "\n",
    "    def read_header_lines(self) -> List[str]:\n",
    "        \"\"\"Return the raw header lines (including line 1).\"\"\"\n",
    "        n = self.info.header_length\n",
    "        lines: List[str] = []\n",
    "        with open(self.path, \"r\", encoding=\"utf-8\", errors=\"ignore\") as f:\n",
    "            for _ in range(n):\n",
    "                line = f.readline()\n",
    "                if not line:\n",
    "                    break\n",
    "                lines.append(line.rstrip(\"\\n\"))\n",
    "        return lines\n",
    "\n",
    "    # ----------------------------\n",
    "    # Minimal assumptions: table extraction\n",
    "    # ----------------------------\n",
    "    def read_table(\n",
    "        self,\n",
    "        *,\n",
    "        na_values: Optional[List[Union[str, float, int]]] = None,\n",
    "        strip_colnames: bool = True,\n",
    "    ) -> pd.DataFrame:\n",
    "        \"\"\"\n",
    "        Extract the data table.\n",
    "\n",
    "        Strategy:\n",
    "          - Most ICARTT files place the column header row at line `header_length`.\n",
    "          - So we skip `header_length - 1` lines and let pandas treat the next line as header.\n",
    "\n",
    "        This is general and does not depend on campaign/platform.\n",
    "        \"\"\"\n",
    "        skiprows = max(self.info.header_length - 1, 0)\n",
    "\n",
    "        # Many ICT files use -9999, -99999, etc., but we won't assume; allow caller to pass.\n",
    "        # We'll also attempt to auto-detect common missing indicators from header if possible.\n",
    "        if na_values is None:\n",
    "            na_values = self._guess_missing_values()\n",
    "\n",
    "        df = pd.read_csv(\n",
    "            self.path,\n",
    "            skiprows=skiprows,\n",
    "            sep=\",\",\n",
    "            encoding = \"latin-1\",\n",
    "            encoding_errors = \"ignore\",\n",
    "            engine=\"python\",\n",
    "            na_values=na_values,\n",
    "        )\n",
    "\n",
    "        if strip_colnames:\n",
    "            df.columns = [str(c).strip() for c in df.columns]\n",
    "\n",
    "        return df\n",
    "\n",
    "    # ----------------------------\n",
    "    # Best-effort metadata parsing\n",
    "    # ----------------------------\n",
    "    def read_metadata(self) -> Dict[str, str]:\n",
    "        \"\"\"\n",
    "        Best-effort metadata extraction.\n",
    "\n",
    "        Returns a dict of key metadata fields when the header matches common ICARTT layouts.\n",
    "        If parsing fails, returns what it can without throwing.\n",
    "        \"\"\"\n",
    "        lines = self.read_header_lines()\n",
    "        meta: Dict[str, str] = {}\n",
    "\n",
    "        # Common ICARTT: line indices below assume a conventional layout often used with FFI=1001.\n",
    "        # We'll guard everything with length checks.\n",
    "        def safe(i: int) -> str:\n",
    "            return lines[i].strip() if 0 <= i < len(lines) else \"\"\n",
    "\n",
    "        meta[\"path\"] = str(self.path)\n",
    "        meta[\"header_length\"] = str(self.info.header_length)\n",
    "        meta[\"ffi\"] = self.info.ffi\n",
    "\n",
    "        # These are common but not guaranteed. Keep them best-effort.\n",
    "        meta[\"pi\"] = safe(1)\n",
    "        meta[\"organization\"] = safe(2)\n",
    "        meta[\"data_description\"] = safe(3)\n",
    "        meta[\"mission\"] = safe(4)\n",
    "        meta[\"volume_info\"] = safe(5)\n",
    "        meta[\"date_info\"] = safe(6)\n",
    "        meta[\"data_interval\"] = safe(7)\n",
    "        meta[\"independent_variable\"] = safe(8)\n",
    "        meta[\"seconds\"] = safe(9)\n",
    "\n",
    "        return {k: v for k, v in meta.items() if v}\n",
    "\n",
    "    def read_variable_defs(self) -> List[VariableDef]:\n",
    "        \"\"\"\n",
    "        Best-effort variable definitions, primarily for common FFI=1001 layout:\n",
    "          - line 10: number of dependent variables\n",
    "          - line 12+: variable definition lines (often \"NAME, UNIT, DESCRIPTION...\")\n",
    "\n",
    "        If layout doesn't match, returns empty list.\n",
    "        \"\"\"\n",
    "        lines = self.read_header_lines()\n",
    "\n",
    "        # Attempt the common ICARTT/FFI=1001 positions\n",
    "        # Line 10 (0-index 9) is often number of dependent variables.\n",
    "        if len(lines) < 11:\n",
    "            return []\n",
    "\n",
    "        try:\n",
    "            n_dep = int(lines[9].strip())\n",
    "        except Exception:\n",
    "            return []\n",
    "\n",
    "        start = 12  # 0-index start of var definition block in common layout\n",
    "        block = lines[start : start + n_dep]\n",
    "        out: List[VariableDef] = []\n",
    "\n",
    "        for ln in block:\n",
    "            parts = [p.strip() for p in ln.split(\",\")]\n",
    "            if not parts:\n",
    "                continue\n",
    "            name = parts[0]\n",
    "            unit = parts[1] if len(parts) > 1 else None\n",
    "            desc = \",\".join(parts[2:]).strip() if len(parts) > 2 else None\n",
    "            out.append(VariableDef(name=name, unit=unit or None, description=desc or None))\n",
    "\n",
    "        # Attach per-variable missing if we can infer it (optional)\n",
    "        miss_map = self._guess_per_variable_missing()\n",
    "        if miss_map:\n",
    "            out = [\n",
    "                VariableDef(v.name, v.unit, v.description, miss_map.get(v.name))\n",
    "                for v in out\n",
    "            ]\n",
    "\n",
    "        return out\n",
    "\n",
    "    # ----------------------------\n",
    "    # Missing-value handling\n",
    "    # ----------------------------\n",
    "    def _guess_missing_values(self) -> List[Union[str, float, int]]:\n",
    "        \"\"\"\n",
    "        Heuristic: try to extract missing indicators from the header.\n",
    "        Falls back to common sentinel values.\n",
    "\n",
    "        Many ICT files have a line describing missing indicators (often around line 12),\n",
    "        but formats vary. We keep this conservative.\n",
    "        \"\"\"\n",
    "        lines = self.read_header_lines()\n",
    "        candidates: List[Union[str, float, int]] = []\n",
    "\n",
    "        # Scan header for something that looks like a missing indicator list: \"-9999\" etc.\n",
    "        for ln in lines[: min(len(lines), 200)]:\n",
    "            # find numeric sentinels that look like -9999, -99999, 9999 etc.\n",
    "            for tok in ln.replace(\",\", \" \").split():\n",
    "                if tok.startswith((\"-\", \"+\")) and tok[1:].isdigit():\n",
    "                    val = int(tok)\n",
    "                    # common missing sentinels are large magnitude\n",
    "                    if abs(val) >= 999:\n",
    "                        candidates.append(val)\n",
    "\n",
    "        # De-duplicate while preserving order\n",
    "        seen = set()\n",
    "        ordered = []\n",
    "        for v in candidates:\n",
    "            if v not in seen:\n",
    "                seen.add(v)\n",
    "                ordered.append(v)\n",
    "\n",
    "        # Add very common defaults if we found nothing\n",
    "        if not ordered:\n",
    "            ordered = [-9999, -99999, -8888, 9999, 99999]\n",
    "\n",
    "        return ordered\n",
    "\n",
    "    def _guess_per_variable_missing(self) -> Dict[str, float]:\n",
    "        \"\"\"\n",
    "        Some ICARTT headers specify per-variable missing indicators.\n",
    "        This is not standardized across all producers; implement only as a best-effort hook.\n",
    "\n",
    "        Returns {} if nothing reliable is found.\n",
    "        \"\"\"\n",
    "        # For now, keep minimal: many files effectively use a single sentinel across columns.\n",
    "        # You can extend this if you encounter a known pattern you want to support.\n",
    "        return {}\n",
    "\n",
    "    # ----------------------------\n",
    "    # Exports\n",
    "    # ----------------------------\n",
    "    def to_csv(\n",
    "        self,\n",
    "        out: Optional[PathLike] = None,\n",
    "        *,\n",
    "        na_values: Optional[List[Union[str, float, int]]] = None,\n",
    "        strip_colnames: bool = True,\n",
    "    ) -> Path:\n",
    "        df = self.read_table(na_values=na_values, strip_colnames=strip_colnames)\n",
    "        out_path = Path(out) if out else self.path.with_suffix(\".csv\")\n",
    "        df.to_csv(out_path, index=False)\n",
    "        return out_path\n",
    "\n",
    "    def to_parquet(\n",
    "        self,\n",
    "        out: Optional[PathLike] = None,\n",
    "        *,\n",
    "        na_values: Optional[List[Union[str, float, int]]] = None,\n",
    "        strip_colnames: bool = True,\n",
    "    ) -> Path:\n",
    "        df = self.read_table(na_values=na_values, strip_colnames=strip_colnames)\n",
    "        out_path = Path(out) if out else self.path.with_suffix(\".parquet\")\n",
    "        df.to_parquet(out_path, index=False)\n",
    "        return out_path\n",
    "\n",
    "open(\"icartt/_init_.py\", \"w\").close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90d85d9e",
   "metadata": {},
   "source": [
    "# Combine Multiple Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "c46e7e21",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "folder = \"C:\\\\Users\\\\megon\\\\OneDrive\\\\Documents\\\\Loyola\\\\4th Spring\\\\STAT 370\\\\STAQS_Alt_Geo\"\n",
    "\n",
    "file_paths = []\n",
    "for entry in os.scandir(folder):\n",
    "    if entry.is_file():\n",
    "        file_paths += [entry.path]\n",
    "\n",
    "format = '%Y, %m, %d'\n",
    "        \n",
    "combined_df = pd.DataFrame()\n",
    "for file in file_paths:\n",
    "    r = ICARTTReader(file)\n",
    "    df = r.read_table()\n",
    "    meta = r.read_metadata()\n",
    "    vars_ = r.read_variable_defs()\n",
    "    \n",
    "    #find start date/time\n",
    "    start_date = datetime.strptime(str(meta.get(\"date_info\"))[0:12], format)\n",
    "    start_time = timedelta(seconds = int(meta.get(\"seconds\")))\n",
    "    start_datetime = start_date + start_time\n",
    "    \n",
    "    #find columns that have UTC seconds (Start_UTC, Seconds_UTC, etc.)\n",
    "    time_columns = [col for col in df.columns if \"UTC\" in col.upper()]\n",
    "    \n",
    "    #create new column with full date listed\n",
    "    for col in time_columns:\n",
    "        new_col_name = col.replace(\"_UTC\", \"_Datetime\")\n",
    "        df[new_col_name] = start_datetime + pd.to_timedelta(df[col], unit = \"s\")\n",
    "   \n",
    "    combined_df = pd.concat([combined_df, df], ignore_index = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "b93a485c",
   "metadata": {},
   "outputs": [],
   "source": [
    "out_path = Path(f\"{folder}.csv\")\n",
    "csv_path = combined_df.to_csv(out_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
